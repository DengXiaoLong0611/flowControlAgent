import gradio as gr
import os
import json
from llama_index.core import StorageContext, load_index_from_storage, VectorStoreIndex, SimpleDirectoryReader
from llama_index.core.chat_engine import ContextChatEngine
from llama_index.llms.openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå¼ºåˆ¶è¦†ç›–ï¼‰
load_dotenv(override=True)

# å½“å‰è„šæœ¬æ ¹ç›®å½•ä¸‹çš„ pdf ç›®å½•
PROJECT_ROOT = os.path.dirname(__file__)
PDF_DIR = os.path.join(PROJECT_ROOT, "train_data", "pdfs")
INDEX_STATS_FILE = os.path.join(PROJECT_ROOT, "..", "..", "data", "index", "index_stats.json")

# é…ç½®OpenAIæ¨¡å‹
llm = OpenAI(
    model="gpt-4o", 
    temperature=0.1,  # é™ä½åˆ°0.2ï¼Œä½¿å›ç­”æ›´ç†æ€§å‡†ç¡®
    max_tokens=16000,  # å¢åŠ åˆ°64000
    context_window=16000
)

# åŠ è½½ç°æœ‰ç´¢å¼•
def load_engine(index_dir=r"data\index") -> ContextChatEngine:
    storage_context = StorageContext.from_defaults(persist_dir=index_dir)
    index = load_index_from_storage(storage_context)
    return index.as_chat_engine(chat_mode="context", verbose=True, llm=llm)

chat_engine = load_engine()
    
# é—®ç­”å‡½æ•°
def query_engine(prompt):
    response = chat_engine.chat(prompt)
    return response.response

# è·å–è®­ç»ƒæ—¶æˆåŠŸåŠ è½½çš„PDFæ–‡ä»¶åï¼ˆä» index_stats.jsonï¼‰
def get_trained_pdf_list():
    try:
        if not os.path.exists(INDEX_STATS_FILE):
            return []
        with open(INDEX_STATS_FILE, "r", encoding="utf-8") as f:
            stats = json.load(f)
        return stats.get("file_list", [])
    except Exception as e:
        print(f"âš ï¸ è·å–è®­ç»ƒæ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
        return []

# ä¸Šä¼ æ–°PDFåæ›´æ–°ç´¢å¼•ï¼ˆä¿å­˜æ–‡ä»¶ï¼‰
def upload_and_update(file_obj):
    try:
        file_path = file_obj.name
        file_name = os.path.basename(file_path)
        save_path = os.path.join(PDF_DIR, file_name)

        os.makedirs(PDF_DIR, exist_ok=True)
        with open(file_path, "rb") as src, open(save_path, "wb") as dst:
            dst.write(src.read())

        return f"âœ… ä¸Šä¼ æˆåŠŸ: {file_name}ï¼Œè¯·é‡æ–°è®­ç»ƒæˆ–é‡è½½ç´¢å¼•ã€‚"
    except Exception as e:
        return f"âŒ ä¸Šä¼ å¤±è´¥: {str(e)}"

# åˆ·æ–°æ–‡æ¡£æ˜¾ç¤ºé€»è¾‘ï¼ˆä»…æ˜¾ç¤ºçœŸæ­£è®­ç»ƒæˆåŠŸçš„æ–‡æ¡£ï¼‰
def refresh_pdf_list():
    pdf_list = get_trained_pdf_list()
    if pdf_list:
        return "### ğŸ“˜ å½“å‰çŸ¥è¯†åº“ä¸­å·²è®­ç»ƒçš„PDFæ–‡ä»¶ï¼š\n\n" + "\n".join([f"- ğŸ“„ **{name}**" for name in pdf_list])
    else:
        return "âš ï¸ æš‚æ— å·²è®­ç»ƒæ–‡æ¡£ã€‚è¯·è¿è¡Œæ„å»ºè„šæœ¬è¿›è¡Œè®­ç»ƒã€‚"

# UI ç»„ä»¶
with gr.Blocks(title="åœŸæœ¨å·¥ç¨‹ä¸“å®¶çŸ¥è¯†é—®ç­”ç³»ç»Ÿ") as demo:
    gr.Markdown("## ğŸ—ï¸ åœŸæœ¨å·¥ç¨‹ä¸“å®¶çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")

    with gr.Row():
        with gr.Column():
            question_input = gr.Textbox(lines=3, placeholder="è¯·è¾“å…¥é—®é¢˜", label="æé—® / æŸ¥è¯¢")
            submit_btn = gr.Button("Submit", variant="primary")
            clear_btn = gr.Button("Clear")

        with gr.Column():
            answer_output = gr.Textbox(lines=10, label="ä¸“å®¶å›ç­”")

    submit_btn.click(fn=query_engine, inputs=question_input, outputs=answer_output)
    clear_btn.click(fn=lambda: "", outputs=answer_output)

    with gr.Accordion("ğŸ“š å·²è®­ç»ƒçš„PDFæ–‡æ¡£åˆ—è¡¨", open=False):
        pdf_display = gr.Markdown(refresh_pdf_list)
        refresh_button = gr.Button("ğŸ”„ åˆ·æ–°æ–‡æ¡£åˆ—è¡¨")
        refresh_button.click(fn=refresh_pdf_list, outputs=pdf_display)

    with gr.Accordion("ğŸ“¤ ä¸Šä¼ æ–°çš„PDFçŸ¥è¯†æ–‡æ¡£", open=False):
        file_input = gr.File(file_types=[".pdf"], label="ä¸Šä¼ PDF")
        upload_result = gr.Textbox(label="ä¸Šä¼ çŠ¶æ€")
        file_input.change(fn=upload_and_update, inputs=file_input, outputs=upload_result)

    gr.Markdown("---")
    gr.Markdown("ğŸ“˜ å¦‚éœ€ä½¿ä¸Šä¼ çš„æ–‡ä»¶ç«‹å³ç”Ÿæ•ˆï¼Œè¯·è¿è¡ŒçŸ¥è¯†åº“é‡æ„è„šæœ¬ã€‚")

demo.launch()
